---
layout: post
title: Setting Up an AWS Lab for Graphics Programming
date: '2024-06-21'
categories: [AWS, lab, GPU, graphics]
excerpt_separator: <!--more-->
---

This post will builds upon
[Setting Up an AWS Lab]({{ site.baseurl }}/2024/05/27aws-lab-setup/)
in so much so that we assume you have a working IAM role that you can use to execute
AWS API calls.
We will use this foundation to outline a Terraform workspace to spin up GPU and non-GPU instances for graphics programming.

Our main motivation will be to build everything we need to work on
[Introduction to 3D Game Programming with Direct3D 12.0](http://www.d3dcoder.net/d3d12.htm)
and on
[https://learnopengl.com/](https://learnopengl.com/).

<!--more-->

You can go ahead and continue reading, just be mindful that whenever we write things such as
```
./run-cmd-in-shell.sh aws sts get-caller-identity
```

The `./run-cmd-in-shell.sh` is a wrapper script we described in that previous post that allows us to run commands with a valid set of temporary IAM IAM role credentials.

Also keep in mind that our configurations are very 1Password centric since no one should be routinely having any sort of IAM user credentials in plain text or in a file on disk - but we also don't yet need to configure SSO access or anything of the sort.


## Table of Contents
* TOC
{:toc}

---

## Roadmap


---

## Requirements

We recommend you use [github.com/tfutils/tfenv](https://github.com/tfutils/tfenv) to manage the Terraform versions you will need.

For this example we did
```
tfenv init
tfenv install 1.8.4
tfenv use 1.8.4
```

You'll also need

```
brew install jq
```


---

## Our Starting Point

We will begin our travels with the following chatGPT generated program

```c++
/*
    g++ -c opengl_test.cpp -I/usr/include/GL
    g++ -o opengl_test opengl_test.o -lGL -lGLU -lglut
*/
#include <GL/glut.h>

void display() {
    glClear(GL_COLOR_BUFFER_BIT);
    
    glBegin(GL_TRIANGLES);
    glColor3f(1.0f, 0.0f, 0.0f);  // Red
    glVertex2f(-0.5f, -0.5f);
    glColor3f(0.0f, 1.0f, 0.0f);  // Green
    glVertex2f(0.5f, -0.5f);
    glColor3f(0.0f, 0.0f, 1.0f);  // Blue
    glVertex2f(0.0f, 0.5f);
    glEnd();
    
    glFlush();
}

int main(int argc, char** argv) {
    glutInit(&argc, argv);
    glutCreateWindow("OpenGL Test");
    glutDisplayFunc(display);
    
    glutMainLoop();
    
    return 0;
}
```

This scriot came about because we were working through an example in
[CUDA by Example: An Introduction to General-Purpose GPU Programming](https://developer.nvidia.com/cuda-example),
the one about the Julia sets, and we wanted to learn more about graphics and annimations.

So our first test was to try to get that script to run and to see whatever it was that it was producing.


## Our Terraform code

We will go right ahead and just show all of the Terraform we have been using.
We will go over it as we go on, but we are opting to give all the TF from the beginning as otherwise it may get confusing what we need to add, change, remove, as we discover things.

A copy of the code we use can be found in
[github.com/seafoodfry/seafoodfry-code/gpu-sandbox](https://github.com/seafoodfry/seafoodfry-code/tree/main/gpu-sandbox).


---

## Knowing the limits of `ssh -X`

Our first attempt at getting into graphics was to simply run ssh and enable X111 forwarding via a command such as

```
ssh -X ec2-user@${EC2}
```

First set `var.dev_machines` to `1` and `var.gpus` and `var.windows_gpu_machines` to `0``, and then run

```bash
./run-cmd-in-shell.sh terraform init
```

Now set the `my_ip` variable as follows
```
export TF_VAR_my_ip=$(curl https://cloudflare.com/cdn-cgi/trace | grep ip | awk -F= '{print $2}')
```
(We could have also set it using `-var my_ip="x.x.x.x"`.)

Then,
```
./run-cmd-in-shell.sh terraform plan -out a.plan
```

And apply the plan
```
./run-cmd-in-shell.sh terraform apply a.plan
```

You will get a plain old t3 EC2 running Amazon Linux 2.

**Note:** we initially tried doing the X111 forwarding on Amazon Linux 2023, AL2023,
but we discovered that we couldn't even install apps such as `xeyes` to test that our
ssh forwarding was correct.
After a lot of googling, chatGPTing, and Claude-ing we sort of gave up on this approach and found this AWS docs page
[Prerequisites for Linux NICE DCV servers](https://docs.aws.amazon.com/dcv/latest/adminguide/setting-up-installing-linux-prereq.html).
Which in the "Install a desktop environment and desktop manager", in the "Amazon Linux 2" tab, it mentions the following:

> Currently, NICE DCV is not compatible with Amazon Linux 2023.
> AL2023 does not include a graphical desktop environment which is required for
> NICE DCV to run.

This gave us the hint that AL2 was the OS to use - and that we should try something like NICE DCV but more on that later.

Anyways, that's why we ended up using the AMI `ami-04064f2a9939d4f29`.
You can get more info on it by running

```bash
./run-cmd-in-shell.sh aws ec2 describe-images --image-ids ami-04064f2a9939d4f29
```

Anyway, back to our adventure.
If you look at the user data for the non-GPU linux EC2 we just created, it install
`freeglut`, which is the library used by the "CUDA by example" book, and the library used by our `opengl_test.cpp` file we included above.

Once the EC2 is up, go on and SSH into it
```
export EC2="<public DNS name>"
```

```
ssh -X ec2-user@${EC2}
```

At this point, if you type
```
xeyes
```

Then you should see a cute lil pop up.
Otherwise you need to go figure out how to get the X111 forwarding through SSH configured.

But assuming, you saw the eyes, let's go and copy our test program into the EC2 and let's try compiling it
```
scp ./opengl_test.cpp ec2-user@${EC2}:/home/ec2-user
```

The compilation instructions are in the header of the file but for completeness
You compile with
```
g++ -c opengl_test.cpp -I/usr/include/GL
```
and link with
```
g++ -o opengl_test opengl_test.o -lGL -lGLU -lglut
```

Both of these should work, otherwise freeglut was not installed correctly.

Running the progra should then give you this error
```
$ ./opengl_test
freeglut (./opengl_test):  ERROR:  Internal error <FBConfig with necessary capabilities not found> in function fgOpenWindow
```

You can google and AI all you want but this error essentially means that we need a "remote desktop".
Spoiler, using
[NICE DCV](https://docs.aws.amazon.com/dcv/latest/adminguide/what-is-dcv.html)
will provide us with the perfect environment to actually do graphics programming in Linux instances.
(We will talk about Windows in a later post when we talk about DirectX.)

Also, we will proceed with running NICE DCV on a GPU instance because after figuring out that NICE DCV might be our solution, we read
[Prerequisites for Linux NICE DCV servers](https://docs.aws.amazon.com/dcv/latest/adminguide/setting-up-installing-linux-prereq.html).
and saw that not only is AL2023 not suitable for graphics programming, but when we attempt to do graphics programming without a GPU we also need to install things such as the XDummy driver, which allows the X server to run with a virtual framebuffer when no real GPU is present.

---

## Spining Up a GPU

### Finding a GPU AMI

While checking out what AMIs were recommended through the launch wizard, we came across the
AMI ID `ami-0296a329aeec73707` published by amazon with the title
"Deep Learning OSS Nvidia Driver AMI GPU PyTorch 2.2.0 (Amazon Linux 2) 20240521".
We can query info about it as follows:

```
./run-cmd-in-shell.sh aws ec2 describe-images --owners amazon --image-ids ami-0296a329aeec73707
```

We kept searching for AMIs with the following query

```
./run-cmd-in-shell.sh aws ec2 describe-images --owner 898082745236 --filters "Name=platform-details,Values=Linux/UNIX" "Name=architecture,Values=x86_64"  "Name=name,Values=*Amazon Linux 2*" "Name=creation-date,Values=2024-05*" "Name=description,Values=*G4dn*" > out.json
```

and found this candidate

```json
{
    "Architecture": "x86_64",
    "CreationDate": "2024-05-22T09:42:47.000Z",
    "ImageId": "ami-0c4b8684fc96c1de0",
    "ImageLocation": "amazon/Deep Learning OSS Nvidia Driver AMI (Amazon Linux 2) Version 78.2",
    "ImageType": "machine",
    "Public": true,
    "OwnerId": "898082745236",
    "PlatformDetails": "Linux/UNIX",
    "UsageOperation": "RunInstances",
    "State": "available",
    "BlockDeviceMappings": [
        {
            "DeviceName": "/dev/xvda",
            "Ebs": {
                "DeleteOnTermination": true,
                "Iops": 3000,
                "SnapshotId": "snap-0af15a9e4c4b2e59c",
                "VolumeSize": 105,
                "VolumeType": "gp3",
                "Throughput": 125,
                "Encrypted": false
            }
        }
    ],
    "Description": "Supported EC2 instances: G4dn, G5, G6, Gr6, P4d, P4de, P5. PyTorch-2.1, TensorFlow-2.16. Release notes: https://docs.aws.amazon.com/dlami/latest/devguide/appendix-ami-release-notes.html",
    "EnaSupport": true,
    "Hypervisor": "xen",
    "ImageOwnerAlias": "amazon",
    "Name": "Deep Learning OSS Nvidia Driver AMI (Amazon Linux 2) Version 78.2",
    "RootDeviceName": "/dev/xvda",
    "RootDeviceType": "ebs",
    "SriovNetSupport": "simple",
    "VirtualizationType": "hvm",
    "DeprecationTime": "2026-05-22T09:42:47.000Z"
},
```
